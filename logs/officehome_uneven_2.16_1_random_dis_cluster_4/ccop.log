===2023-08-05 00:10:43===
===Setting===
    dataset: officehome
    lr: 0.01
    batch: 64
    iters: 0
    wk_iters: 1
    si: False
    domain_num: 4
    quantile: 0
    power_cs: 1
    std_rw: False
    gender_label: False
    binary_race: False
    save_iter: -1
    mix5: False
    power_relu: 1
    Ea_val: False
data_number=[21,27,35,45,58,75,97,126,163,210,30,45,68,101,152,61,122,85,
client_nums=[10,5,2,1,]
len_dataset=[1435,664,307,142,]
domain number = 4
multiply 100 for Ea!
use train loss for Ea
===2023-08-05 00:10:48===
===2023-08-05 00:11:45===
===Setting===
    dataset: officehome
    lr: 0.01
    batch: 64
    iters: 2
    wk_iters: 1
    si: False
    domain_num: 4
    quantile: 0
    power_cs: 1
    std_rw: False
    gender_label: False
    binary_race: False
    save_iter: -1
    mix5: False
    power_relu: 1
    Ea_val: False
data_number=[21,27,35,45,58,75,97,126,163,210,30,45,68,101,152,61,122,85,
client_nums=[10,5,2,1,]
len_dataset=[1435,664,307,142,]
domain number = 4
multiply 100 for Ea!
use train loss for Ea
============ Train epoch 0 ============
cnt=[1, 1, 2, 14, ]
power_decay: 0.9, powerI: 0.9500, powerC: 0.0500
 Site-Art                       (0) | Train Loss: 4.0845 | Train Acc: 0.0000
 Site-Art                       (3) | Train Loss: 4.1275 | Train Acc: 0.0370
 Site-Art                       (3) | Train Loss: 4.1297 | Train Acc: 0.0286
 Site-Art                       (3) | Train Loss: 4.1554 | Train Acc: 0.0000
 Site-Art                       (3) | Train Loss: 4.0441 | Train Acc: 0.0517
 Site-Art                       (3) | Train Loss: 4.1568 | Train Acc: 0.0267
 Site-Art                       (3) | Train Loss: 4.0817 | Train Acc: 0.0206
 Site-Art                       (3) | Train Loss: 4.0981 | Train Acc: 0.0476
 Site-Art                       (3) | Train Loss: 4.1441 | Train Acc: 0.0368
 Site-Art                       (3) | Train Loss: 4.0868 | Train Acc: 0.0476
 Site-RealWorld                 (1) | Train Loss: 4.1532 | Train Acc: 0.0000
 Site-RealWorld                 (3) | Train Loss: 4.1099 | Train Acc: 0.0444
 Site-RealWorld                 (3) | Train Loss: 4.1135 | Train Acc: 0.0441
 Site-RealWorld                 (3) | Train Loss: 4.0824 | Train Acc: 0.0297
 Site-RealWorld                 (3) | Train Loss: 4.1066 | Train Acc: 0.0329
 Site-Clipart                   (2) | Train Loss: 4.1464 | Train Acc: 0.0164
 Site-Clipart                   (2) | Train Loss: 4.2015 | Train Acc: 0.0328
 Site-Product                   (3) | Train Loss: 4.0557 | Train Acc: 0.0118
Average Train Accuracy: 0.0283
 Site-Art                       (0) | Val  Loss: 4.1265 | Val  Acc: 0.0714
 Site-Art                       (3) | Val  Loss: 4.0986 | Val  Acc: 0.1111
 Site-Art                       (3) | Val  Loss: 4.1952 | Val  Acc: 0.0435
 Site-Art                       (3) | Val  Loss: 4.1916 | Val  Acc: 0.0000
 Site-Art                       (3) | Val  Loss: 4.2131 | Val  Acc: 0.0000
 Site-Art                       (3) | Val  Loss: 4.1490 | Val  Acc: 0.0000
 Site-Art                       (3) | Val  Loss: 4.0502 | Val  Acc: 0.0462
 Site-Art                       (3) | Val  Loss: 4.0973 | Val  Acc: 0.0238
 Site-Art                       (3) | Val  Loss: 4.0949 | Val  Acc: 0.0278
 Site-Art                       (3) | Val  Loss: 4.1389 | Val  Acc: 0.0286
 Site-RealWorld                 (1) | Val  Loss: 3.9694 | Val  Acc: 0.0000
 Site-RealWorld                 (3) | Val  Loss: 4.0941 | Val  Acc: 0.0667
 Site-RealWorld                 (3) | Val  Loss: 4.0624 | Val  Acc: 0.0222
 Site-RealWorld                 (3) | Val  Loss: 3.9879 | Val  Acc: 0.0299
 Site-RealWorld                 (3) | Val  Loss: 4.1014 | Val  Acc: 0.0693
 Site-Clipart                   (2) | Val  Loss: 4.1860 | Val  Acc: 0.0250
 Site-Clipart                   (2) | Val  Loss: 4.2110 | Val  Acc: 0.0000
 Site-Product                   (3) | Val  Loss: 4.0732 | Val  Acc: 0.0357
Average Valid Accuracy: 0.0334
 Best site-Art                      (0)  | Epoch:0 | Val Acc: 0.0714
 Best site-Art                      (3)  | Epoch:0 | Val Acc: 0.1111
 Best site-Art                      (3)  | Epoch:0 | Val Acc: 0.0435
 Best site-Art                      (3)  | Epoch:0 | Val Acc: 0.0000
 Best site-Art                      (3)  | Epoch:0 | Val Acc: 0.0000
 Best site-Art                      (3)  | Epoch:0 | Val Acc: 0.0000
 Best site-Art                      (3)  | Epoch:0 | Val Acc: 0.0462
 Best site-Art                      (3)  | Epoch:0 | Val Acc: 0.0238
 Best site-Art                      (3)  | Epoch:0 | Val Acc: 0.0278
 Best site-Art                      (3)  | Epoch:0 | Val Acc: 0.0286
 Best site-RealWorld                (1)  | Epoch:0 | Val Acc: 0.0000
 Best site-RealWorld                (3)  | Epoch:0 | Val Acc: 0.0667
 Best site-RealWorld                (3)  | Epoch:0 | Val Acc: 0.0222
 Best site-RealWorld                (3)  | Epoch:0 | Val Acc: 0.0299
 Best site-RealWorld                (3)  | Epoch:0 | Val Acc: 0.0693
 Best site-Clipart                  (2)  | Epoch:0 | Val Acc: 0.0250
 Best site-Clipart                  (2)  | Epoch:0 | Val Acc: 0.0000
 Best site-Product                  (3)  | Epoch:0 | Val Acc: 0.0357
 Saving the gmap checkpoint to ../checkpoint/fed_officehome_uneven_2.16_1/ccop_q=1_gmap...
 Saving the local and server checkpoint to ../checkpoint/fed_officehome_uneven_2.16_1/ccop_q=1...
============ Train epoch 1 ============
cnt=[2, 1, 13, 2, ]
power_decay: 0.9, powerI: 0.9050, powerC: 0.0950
 Site-Art                       (0) | Train Loss: 4.0181 | Train Acc: 0.0476
 Site-Art                       (0) | Train Loss: 3.9385 | Train Acc: 0.0741
 Site-Art                       (2) | Train Loss: 4.0563 | Train Acc: 0.1429
 Site-Art                       (2) | Train Loss: 4.0692 | Train Acc: 0.0444
 Site-Art                       (2) | Train Loss: 3.9974 | Train Acc: 0.0517
 Site-Art                       (2) | Train Loss: 3.9137 | Train Acc: 0.0933
 Site-Art                       (2) | Train Loss: 3.9744 | Train Acc: 0.0825
 Site-Art                       (2) | Train Loss: 3.9908 | Train Acc: 0.1032
 Site-Art                       (2) | Train Loss: 4.0251 | Train Acc: 0.0920
 Site-Art                       (2) | Train Loss: 3.9424 | Train Acc: 0.1190
 Site-RealWorld                 (2) | Train Loss: 3.9956 | Train Acc: 0.1333
 Site-RealWorld                 (2) | Train Loss: 4.0069 | Train Acc: 0.0889
 Site-RealWorld                 (2) | Train Loss: 3.9482 | Train Acc: 0.0735
 Site-RealWorld                 (2) | Train Loss: 3.9708 | Train Acc: 0.0594
 Site-RealWorld                 (2) | Train Loss: 4.0056 | Train Acc: 0.0855
 Site-Clipart                   (3) | Train Loss: 4.0563 | Train Acc: 0.1148
 Site-Clipart                   (3) | Train Loss: 4.1519 | Train Acc: 0.0410
 Site-Product                   (1) | Train Loss: 3.9676 | Train Acc: 0.0824
Average Train Accuracy: 0.0850
 Site-Art                       (0) | Val  Loss: 3.9478 | Val  Acc: 0.0714
 Site-Art                       (0) | Val  Loss: 4.0067 | Val  Acc: 0.1111
 Site-Art                       (2) | Val  Loss: 4.1054 | Val  Acc: 0.0870
 Site-Art                       (2) | Val  Loss: 4.0749 | Val  Acc: 0.0000
 Site-Art                       (2) | Val  Loss: 4.1127 | Val  Acc: 0.0513
 Site-Art                       (2) | Val  Loss: 3.9870 | Val  Acc: 0.0600
 Site-Art                       (2) | Val  Loss: 3.7497 | Val  Acc: 0.0923
 Site-Art                       (2) | Val  Loss: 3.9556 | Val  Acc: 0.1071
 Site-Art                       (2) | Val  Loss: 3.9506 | Val  Acc: 0.0833
 Site-Art                       (2) | Val  Loss: 3.9847 | Val  Acc: 0.0786
 Site-RealWorld                 (2) | Val  Loss: 3.8738 | Val  Acc: 0.2000
 Site-RealWorld                 (2) | Val  Loss: 3.8588 | Val  Acc: 0.1000
 Site-RealWorld                 (2) | Val  Loss: 3.9678 | Val  Acc: 0.0889
 Site-RealWorld                 (2) | Val  Loss: 3.8660 | Val  Acc: 0.0448
 Site-RealWorld                 (2) | Val  Loss: 3.9685 | Val  Acc: 0.0792
 Site-Clipart                   (3) | Val  Loss: 4.1342 | Val  Acc: 0.0250
 Site-Clipart                   (3) | Val  Loss: 4.1175 | Val  Acc: 0.0370
 Site-Product                   (1) | Val  Loss: 4.0242 | Val  Acc: 0.0893
Average Valid Accuracy: 0.0781
 Best site-Art                      (0)  | Epoch:1 | Val Acc: 0.0714
 Best site-Art                      (0)  | Epoch:1 | Val Acc: 0.1111
 Best site-Art                      (2)  | Epoch:1 | Val Acc: 0.0870
 Best site-Art                      (2)  | Epoch:1 | Val Acc: 0.0000
 Best site-Art                      (2)  | Epoch:1 | Val Acc: 0.0513
 Best site-Art                      (2)  | Epoch:1 | Val Acc: 0.0600
 Best site-Art                      (2)  | Epoch:1 | Val Acc: 0.0923
 Best site-Art                      (2)  | Epoch:1 | Val Acc: 0.1071
 Best site-Art                      (2)  | Epoch:1 | Val Acc: 0.0833
 Best site-Art                      (2)  | Epoch:1 | Val Acc: 0.0786
 Best site-RealWorld                (2)  | Epoch:1 | Val Acc: 0.2000
 Best site-RealWorld                (2)  | Epoch:1 | Val Acc: 0.1000
 Best site-RealWorld                (2)  | Epoch:1 | Val Acc: 0.0889
 Best site-RealWorld                (2)  | Epoch:1 | Val Acc: 0.0448
 Best site-RealWorld                (2)  | Epoch:1 | Val Acc: 0.0792
 Best site-Clipart                  (3)  | Epoch:1 | Val Acc: 0.0250
 Best site-Clipart                  (3)  | Epoch:1 | Val Acc: 0.0370
 Best site-Product                  (1)  | Epoch:1 | Val Acc: 0.0893
 Saving the gmap checkpoint to ../checkpoint/fed_officehome_uneven_2.16_1/ccop_q=1_gmap...
 Saving the local and server checkpoint to ../checkpoint/fed_officehome_uneven_2.16_1/ccop_q=1...
===2023-08-05 00:19:13===
===2023-08-05 12:24:29===
===Setting===
    dataset: officehome
    lr: 0.01
    batch: 64
    iters: 0
    wk_iters: 1
    si: False
    domain_num: 4
    quantile: 0
    power_cs: 1
    std_rw: False
    gender_label: False
    binary_race: False
    save_iter: -1
    mix5: False
    power_relu: 1
    Ea_val: False
data_number=[4,5,7,9,12,16,21,27,35,45,6,9,14,21,32,13,26,18,
client_nums=[10,5,2,1,]
len_dataset=[312,144,66,30,]
domain number = 4
multiply 100 for Ea!
use train loss for Ea
===2023-08-05 12:24:36===
===2023-08-05 12:24:50===
===Setting===
    dataset: officehome
    lr: 0.01
    batch: 64
    iters: 0
    wk_iters: 1
    si: False
    domain_num: 4
    quantile: 0
    power_cs: 1
    std_rw: False
    gender_label: False
    binary_race: False
    save_iter: -1
    mix5: False
    power_relu: 1
    Ea_val: False
data_number=[4,5,7,9,12,16,21,27,35,45,6,9,14,21,32,13,26,18,
client_nums=[10,5,2,1,]
len_dataset=[312,144,66,30,]
domain number = 4
===2023-08-05 12:29:42===
===Setting===
    dataset: officehome
    lr: 0.01
    batch: 64
    iters: 0
    wk_iters: 1
    si: False
    domain_num: 4
    quantile: 0
    power_cs: 1
    std_rw: False
    gender_label: False
    binary_race: False
    save_iter: -1
    mix5: False
    power_relu: 1
    Ea_val: False
data_number=[6,7,10,13,16,21,28,36,47,60,8,13,19,29,43,17,34,24,
client_nums=[10,5,2,1,]
len_dataset=[416,192,88,40,]
domain number = 4
multiply 100 for Ea!
use train loss for Ea
===2023-08-05 12:29:46===
